---
layout: homepage
---

## About Me

I'm a first-year PhD student in [MINE Lab](https://mine-lab-nd.github.io/) of Computer Science and Engineering (CSE) at the [University of Notre Dame](https://www.nd.edu/) starting Fall 2024, supervised by [Prof. Xiangliang Zhang](https://scholar.google.com/citations?user=BhRJe4wAAAAJ&hl=en). I obtained my bachelor's degree from [Sichuan University](https://www.scu.edu.cn/) in 2024. Previously, I was a visiting student under the guidance of [Prof. Lichao Sun](https://lichao-sun.github.io/). This experience was enhanced by mentorship from [Prof. Philip S. Yu](https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=en). Earlier before, I worked under [Prof. Tang Jie](https://keg.cs.tsinghua.edu.cn/jietang/) and [Dr. Xiao Liu](https://scholar.google.com.hk/citations?user=VKI8EhUAAAAJ&hl=zh-CN) at Tsinghua University.

> I am seeking potential research collaborations. If you are interested, please [contact me](&#40;mailto:yhuang37@nd.edu&#41;).

## Research Interests

My research is centered on three pivotal questions:

- **How can we deepen our understanding of the trustworthiness of foundational generative models?** This line of inquiry seeks to develop robust frameworks for evaluating trustworthiness and to identify strategies for enhancing the trustworthiness of these models within specific application domains. This includes: [TrustLLM (ICML'24)](https://arxiv.org/abs/2401.05561), [LLM-as-a-Coauthor (NAACL'24)](https://aclanthology.org/2024.findings-naacl.29/), [Attack LLM Judge (ACM CCS'24)](https://arxiv.org/abs/2403.17710), [FakeGPT (WWW'24)](https://dl.acm.org/doi/abs/10.1145/3589335.3651509), [Multilingual Alignment (EMNLP'24)](https://arxiv.org/abs/2406.14721), [HonestLLM (NeurIPS'24)](https://arxiv.org/abs/2406.00380), [TrustNLP@NAACL'24](https://arxiv.org/abs/2407.16686), and [ObscurePrompt](https://arxiv.org/abs/2406.13662).

- **Is there a superior approach to achieving Artificial General Intelligence (AGI)?** This research emphasizes data-centric methods to enable scalable model alignment and evolution, ensuring that they adhere to human values and ethical paradigms throughout the development process. This includes: [AlignBench (ACL'24)](https://arxiv.org/abs/2311.18743), [Multilingual Alignment (EMNLP'24)](https://arxiv.org/abs/2406.14721), and [UniGen](https://arxiv.org/abs/2406.18966).

- **To what extent can current AI technologies effectively benefit downstream applications?** This research area critically assesses the practical impact of generative models, with a particular focus on their application and AI4Science, exploring its transformative potential and interdisciplinary contributions in fields such as agentic models, social sciences, and beyond. This includes: [MetaTool (ICLR'24)](https://arxiv.org/abs/2310.03128), [PsychometricBench](https://arxiv.org/abs/2406.17675), [AwareBench](https://arxiv.org/abs/2401.17882) and [GUI-World](https://arxiv.org/abs/2406.10819).

## News

- *2024.12* &nbsp; I will join IBM Research as a Research Scientist Intern in 2025 Summer. See you in Cambridge, MA.

- *2024.09*  &nbsp; [HonestLLM](https://arxiv.org/abs/2406.00380) has been accepted by NeurIPS 2024! Congratulations to [Chujie](https://flossiee.github.io/)! Another paper has been accepted by main conference of EMNLP 2024!

- *2024.08* &nbsp; [Attack LLM-as-a-Judge](https://arxiv.org/abs/2403.17710) has been accepted by ACM CCS 2024!

- *2024.07* &nbsp; OpenAI’s Researcher Access Program is Awarded.

- *2024.05* &nbsp; [TrustLLM](https://trustllmbenchmark.github.io/TrustLLM-Website/) has been accepted by ICML 2024! Thanks to all the collaborators. See you in Vienna! Another paper has been accepted by main conference of ACL 2024!

- *2024.03* &nbsp; One paper has been accepted by NAACL 2024! Congratulations to [Qihui](https://mask-hui.github.io/), [Chujie](https://flossiee.github.io/) and [Dongping](https://dongping-chen.github.io/)! Another paper has been accepted as a short paper of WWW 2024!

- *2024.02* &nbsp; Thanks for the invited talk on TrustLLM Project! @ [IBM Research](https://research.ibm.com/)

- *2024.01* &nbsp; [MetaTool](https://arxiv.org/abs/2310.03128) has been accepted by ICLR 2024! Finish research internship at Tsinghua University KEG & Zhipu Inc.!

## Selected Publications

**Disclaimer**: This material is presented to ensure the timely dissemination of scholarly works. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms invoked by each author's copyright.

*: Equal Contribution

- [TrustLLM: Trustworthiness in Large Language Models](https://proceedings.mlr.press/v235/huang24x.html)\\
  **Yue Huang**, Lichao Sun, Haoran Wang, Siyuan Wu, Qihui Zhang, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, Zhengliang Liu, Yixin Liu, Yijue Wang, Zhikun Zhang, Bhavya Kailkhura, Caiming Xiong, et al.\\
  <span style="color: #de724e;">2024 International Conference on Machine Learning (ICML 2024)</span>\\
  (Highlighted by United States Department of Homeland Security (DHS), Invited Talk at IBM Research)\\
  [\[Code&Toolkit\]](https://howiehwong.github.io/TrustLLM/) [\[Website\]](https://trustllmbenchmark.github.io/TrustLLM-Website/) [\[Dataset\]](https://atlas.nomic.ai/map/f64e87d3-c769-4a90-b15d-9dc833acc8ba/8e9d7045-503b-4ba0-bc64-7201cb7aacee?xs=-16.14086&xf=-1.88776&ys=-7.54937&yf=3.88213) [\[Docs.\]](https://howiehwong.github.io/TrustLLM/)

- [MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use](https://arxiv.org/abs/2310.03128)\\
  **Yue Huang**, Jiawen Shi, Yuan Li, Chenrui Fan, Siyuan Wu, Qihui Zhang, Yixin Liu, Pan Zhou, et al.\\
  <span style="color: #de724e;"> The Twelfth International Conference on Learning Representations (ICLR 2024)</span>\\
  [\[Code\]](https://github.com/HowieHwong/MetaTool)

- [1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?](https://arxiv.org/abs/2406.14721)\\
  **Yue Huang**\*, Chenrui Fan\*, Yuan Li, Siyuan Wu, et al.\\
  <span style="color: #de724e;">The 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024)</span>

- [HonestLLM: Toward an Honest and Helpful Large Language Model](https://arxiv.org/abs/2406.00380) \\
  Chujie Gao\*, Siyuan Wu\*, **Yue Huang\***, Dongping Chen\*, Qihui Zhang\*, et al. \\
  <span style="color: #de724e;">Thirty-Eighth Annual Conference on Neural Information Processing Systems (NeurIPS 2024)</span>\\
  [\[Code\]](https://github.com/Flossiee/HonestyLLM)

- [Optimization-based Prompt Injection Attack to LLM-as-a-Judge](https://arxiv.org/abs/2403.17710)\\
  Jiawen Shi, Zenghui Yuan, Yinuo Liu, **Yue Huang**, Pan Zhou, Lichao Sun, Neil Zhenqiang Gong\\
  <span style="color: #de724e;">The ACM Conference on Computer and Communications Security (ACM CCS 2024)</span>\\
  [\[Code\]](https://github.com/ShiJiawenwen/JudgeDeceiver)

- [LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?](https://arxiv.org/abs/2401.05952)\\
  Qihui Zhang\*, Chujie Gao\*, Dongping Chen\*, **Yue Huang**, et al.  
  <span style="color: #de724e;">2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics (Findings of NAACL 2024)</span>\\
  [\[Code\]](https://github.com/Dongping-Chen/MixSet) [\[Website\]](https://llm-coauthor.github.io/)

- [AlignBench: Benchmarking Chinese Alignment of Large Language Models](https://arxiv.org/abs/2311.18743)\\
  Xiao Liu\*, Xuanyu Lei\*, Shengyuan Wang, **Yue Huang**, Zhuoer Feng, et al.\\
  <span style="color: #de724e;">The 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)</span>\\
  [\[Code\]](https://github.com/THUDM/AlignBench) [\[Website\]](https://llmbench.ai/align)

- [From Creation to Clarification: ChatGPT's Journey Through the Fake News Quagmire]()\\
  **Yue Huang**, Kai Shu, Philip S. Yu, Lichao Sun\\
  <span style="color: #de724e;">2024 ACM Web Conference (WWW 2024)</span>

## Talks
- *2024.02* Trustworthiness in Large Language Models @ [IBM Research](https://research.ibm.com/)

- *2024.07* Bias of Large Language Models @ TUM

## Honors and Awards
- *2024.07* OpenAI’s Researcher Access Program and API

- *2024.01* Microsoft Accelerate Foundation Models Research is awarded (Project: [TrustLLM](https://github.com/HowieHwong/TrustLLM) & Lead PI: [Lichao Sun](https://lichao-sun.github.io/))

## Academic Participation

- Journal Reviewer: IEEE Transactions on Artificial Intelligence (TAI), IEEE Transactions on Dependable and Secure Computing (TDSC), IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP),  ACM Transactions on Intelligent Systems and Technology (ACM TIST)

- Conference Reviewer: ICLR, ICDM, EMNLP Demo Track (2024), ACL Rolling Review

- Technical Committee Member of 2024 IEEE Computer Society North America Student Challenge

## Educations

- *2024.09 - Present*, Ph.D, <img src='assets/img/Notre_Dame.png' style='width: 1.2em;'> [University of Notre Dame](https://www.nd.edu/) 
- *2020.09 - 2024.06*, BEng., <img src='assets/img/scu.png' style='width: 1.2em;'> [Sichuan University](https://www.scu.edu.cn/) 


## Internships

- *2023.09 - 2024.01*, Research Intern at <img src='assets/img/thu.png' style='width: 1.2em;'> Tsinghua University KEG & Zhipu AI Inc.